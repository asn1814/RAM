dataset: openassistant2_llama3_preference_train
max_seq_len: 1024
max_num_tokens: 4096
example_shuffle_window: 2000
batch_shuffle_window: 1000
num_prefetch: 4
model: llama3_8b
dtype: bfloat16
data_parallelism: fsdp
fsdp_wrap_granularity: layer
fsdp_reshard_after_forward: true
tensor_parallel_size: 1
activation_checkpointing: true
torch_compile: false
optimizer: adamw
optimizer_config: 
  _type_: fairseq2.optim.factory.AdamWConfig
  lr: 1.0e-6
  betas:
  - 0.9
  - 0.95
  weight_decay: 0.1
lr_scheduler: cosine-annealing
lr_scheduler_config:
  _type_: fairseq2.optim.lr_scheduler.factory.CosineAnnealingLRConfig
  num_warmup_steps: 0
  final_lr: 0.5e-07
gradient_accumulation: 4
max_gradient_norm: null
fp16_loss_scale:
- 128.0
- 0.0001
max_num_steps: 800
max_num_data_epochs: 5
checkpoint_every_n_data_epochs: 1
keep_last_n_checkpoints: 5
publish_metrics_every_n_steps: 5
seed: 1814
profile: null
monitored_gang: false
anomaly_detection: false
criterion: cpo
criterion_config:
  _type_: fairseq2.recipes.lm.preference_finetune.cpo.CPOConfig
  beta: 0.1
  nll_scale: 1